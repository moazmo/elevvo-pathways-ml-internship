{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loan Approval Prediction - Professional ML Pipeline\n",
    "\n",
    "## Project Overview\n",
    "This notebook demonstrates a comprehensive machine learning pipeline for predicting loan approval decisions. The project focuses on:\n",
    "\n",
    "- **Binary Classification**: Predicting loan approval (Approved/Rejected)\n",
    "- **Imbalanced Data Handling**: Using SMOTE and other techniques\n",
    "- **Model Comparison**: Logistic Regression vs Decision Tree vs Ensemble Methods\n",
    "- **Production Readiness**: Complete pipeline with API deployment\n",
    "\n",
    "## Business Context\n",
    "In loan approval, we prioritize **precision** to minimize bad loan approvals (Type I errors) which are costly to the business, while maintaining reasonable **recall** to not miss too many good applicants.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-08-06 17:01:46.893\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.config_loader\u001b[0m:\u001b[36m_load_config\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mConfiguration loaded successfully from config\\config.yaml\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All modules imported successfully\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import custom modules\n",
    "from src.data_loader import DataLoader\n",
    "from src.eda_analyzer import EDAAnalyzer\n",
    "from src.visualizer import LoanDataVisualizer\n",
    "from src.data_preprocessor import LoanDataPreprocessor\n",
    "from src.imbalance_handler import ImbalanceHandler\n",
    "from src.model_trainer import ModelTrainer\n",
    "from src.model_evaluator import ModelEvaluator\n",
    "from src.evaluation_visualizer import EvaluationVisualizer\n",
    "from src.production_pipeline import ProductionPipeline\n",
    "\n",
    "print(\"✅ All modules imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-08-06 17:01:47.272\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.data_loader\u001b[0m:\u001b[36mload_raw_data\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mTarget values after cleaning: ['Approved' 'Rejected']\u001b[0m\n",
      "\u001b[32m2025-08-06 17:01:47.273\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.data_loader\u001b[0m:\u001b[36mload_raw_data\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mCleaned column names: ['loan_id', 'no_of_dependents', 'education', 'self_employed', 'income_annum', 'loan_amount', 'loan_term', 'cibil_score', 'residential_assets_value', 'commercial_assets_value', 'luxury_assets_value', 'bank_asset_value', 'loan_status']\u001b[0m\n",
      "\u001b[32m2025-08-06 17:01:47.274\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.data_loader\u001b[0m:\u001b[36mload_raw_data\u001b[0m:\u001b[36m47\u001b[0m - \u001b[1mData loaded successfully. Shape: (4269, 13)\u001b[0m\n",
      "\u001b[32m2025-08-06 17:01:47.274\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.data_loader\u001b[0m:\u001b[36mload_raw_data\u001b[0m:\u001b[36m48\u001b[0m - \u001b[1mColumns: ['loan_id', 'no_of_dependents', 'education', 'self_employed', 'income_annum', 'loan_amount', 'loan_term', 'cibil_score', 'residential_assets_value', 'commercial_assets_value', 'luxury_assets_value', 'bank_asset_value', 'loan_status']\u001b[0m\n",
      "\u001b[32m2025-08-06 17:01:47.275\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.data_loader\u001b[0m:\u001b[36mvalidate_data_schema\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mData schema validation passed\u001b[0m\n",
      "\u001b[32m2025-08-06 17:01:47.293\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.data_loader\u001b[0m:\u001b[36mload_and_validate\u001b[0m:\u001b[36m139\u001b[0m - \u001b[1mData loading and validation completed successfully\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (4269, 13)\n",
      "Target Distribution: {'Approved': 2656, 'Rejected': 1613}\n",
      "Missing Values: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_id</th>\n",
       "      <th>no_of_dependents</th>\n",
       "      <th>education</th>\n",
       "      <th>self_employed</th>\n",
       "      <th>income_annum</th>\n",
       "      <th>loan_amount</th>\n",
       "      <th>loan_term</th>\n",
       "      <th>cibil_score</th>\n",
       "      <th>residential_assets_value</th>\n",
       "      <th>commercial_assets_value</th>\n",
       "      <th>luxury_assets_value</th>\n",
       "      <th>bank_asset_value</th>\n",
       "      <th>loan_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>9600000</td>\n",
       "      <td>29900000</td>\n",
       "      <td>12</td>\n",
       "      <td>778</td>\n",
       "      <td>2400000</td>\n",
       "      <td>17600000</td>\n",
       "      <td>22700000</td>\n",
       "      <td>8000000</td>\n",
       "      <td>Approved</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4100000</td>\n",
       "      <td>12200000</td>\n",
       "      <td>8</td>\n",
       "      <td>417</td>\n",
       "      <td>2700000</td>\n",
       "      <td>2200000</td>\n",
       "      <td>8800000</td>\n",
       "      <td>3300000</td>\n",
       "      <td>Rejected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>9100000</td>\n",
       "      <td>29700000</td>\n",
       "      <td>20</td>\n",
       "      <td>506</td>\n",
       "      <td>7100000</td>\n",
       "      <td>4500000</td>\n",
       "      <td>33300000</td>\n",
       "      <td>12800000</td>\n",
       "      <td>Rejected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>8200000</td>\n",
       "      <td>30700000</td>\n",
       "      <td>8</td>\n",
       "      <td>467</td>\n",
       "      <td>18200000</td>\n",
       "      <td>3300000</td>\n",
       "      <td>23300000</td>\n",
       "      <td>7900000</td>\n",
       "      <td>Rejected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>9800000</td>\n",
       "      <td>24200000</td>\n",
       "      <td>20</td>\n",
       "      <td>382</td>\n",
       "      <td>12400000</td>\n",
       "      <td>8200000</td>\n",
       "      <td>29400000</td>\n",
       "      <td>5000000</td>\n",
       "      <td>Rejected</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan_id  no_of_dependents     education self_employed  income_annum  \\\n",
       "0        1                 2      Graduate            No       9600000   \n",
       "1        2                 0  Not Graduate           Yes       4100000   \n",
       "2        3                 3      Graduate            No       9100000   \n",
       "3        4                 3      Graduate            No       8200000   \n",
       "4        5                 5  Not Graduate           Yes       9800000   \n",
       "\n",
       "   loan_amount  loan_term  cibil_score  residential_assets_value  \\\n",
       "0     29900000         12          778                   2400000   \n",
       "1     12200000          8          417                   2700000   \n",
       "2     29700000         20          506                   7100000   \n",
       "3     30700000          8          467                  18200000   \n",
       "4     24200000         20          382                  12400000   \n",
       "\n",
       "   commercial_assets_value  luxury_assets_value  bank_asset_value loan_status  \n",
       "0                 17600000             22700000           8000000    Approved  \n",
       "1                  2200000              8800000           3300000    Rejected  \n",
       "2                  4500000             33300000          12800000    Rejected  \n",
       "3                  3300000             23300000           7900000    Rejected  \n",
       "4                  8200000             29400000           5000000    Rejected  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and validate data\n",
    "data_loader = DataLoader()\n",
    "df, data_summary = data_loader.load_and_validate()\n",
    "\n",
    "print(f\"Dataset Shape: {df.shape}\")\n",
    "print(f\"Target Distribution: {data_summary['target_distribution']}\")\n",
    "print(f\"Missing Values: {sum(data_summary['missing_values'].values())}\")\n",
    "\n",
    "# Display first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-08-06 17:01:47.322\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.eda_analyzer\u001b[0m:\u001b[36mrun_comprehensive_eda\u001b[0m:\u001b[36m192\u001b[0m - \u001b[1mStarting comprehensive EDA analysis...\u001b[0m\n",
      "\u001b[32m2025-08-06 17:01:47.327\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.eda_analyzer\u001b[0m:\u001b[36manalyze_missing_values\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mTotal missing values: 0\u001b[0m\n",
      "\u001b[32m2025-08-06 17:01:47.327\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.eda_analyzer\u001b[0m:\u001b[36manalyze_missing_values\u001b[0m:\u001b[36m53\u001b[0m - \u001b[1mRows with missing values: 0\u001b[0m\n",
      "\u001b[32m2025-08-06 17:01:47.329\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.eda_analyzer\u001b[0m:\u001b[36manalyze_target_distribution\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mTarget distribution: {'Approved': 2656, 'Rejected': 1613}\u001b[0m\n",
      "\u001b[32m2025-08-06 17:01:47.330\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.eda_analyzer\u001b[0m:\u001b[36manalyze_target_distribution\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mImbalance ratio: 0.607\u001b[0m\n",
      "\u001b[32m2025-08-06 17:01:47.367\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.eda_analyzer\u001b[0m:\u001b[36mrun_comprehensive_eda\u001b[0m:\u001b[36m207\u001b[0m - \u001b[1mEDA analysis completed successfully\u001b[0m\n",
      "\u001b[32m2025-08-06 17:01:47.368\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.visualizer\u001b[0m:\u001b[36mcreate_eda_report\u001b[0m:\u001b[36m239\u001b[0m - \u001b[1mGenerating comprehensive EDA visualizations...\u001b[0m\n",
      "\u001b[32m2025-08-06 17:01:47.634\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.visualizer\u001b[0m:\u001b[36mplot_missing_values\u001b[0m:\u001b[36m80\u001b[0m - \u001b[1mNo missing values found in the dataset\u001b[0m\n",
      "\u001b[32m2025-08-06 17:01:51.671\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.visualizer\u001b[0m:\u001b[36mcreate_eda_report\u001b[0m:\u001b[36m249\u001b[0m - \u001b[1mEDA visualization report completed\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ EDA completed - check the visualizations above\n"
     ]
    }
   ],
   "source": [
    "# Comprehensive EDA\n",
    "eda_analyzer = EDAAnalyzer(df)\n",
    "eda_results = eda_analyzer.run_comprehensive_eda()\n",
    "\n",
    "# Create visualizations\n",
    "visualizer = LoanDataVisualizer(df)\n",
    "visualizer.create_eda_report(eda_results)\n",
    "\n",
    "print(\"✅ EDA completed - check the visualizations above\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-08-06 17:01:51.680\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.data_preprocessor\u001b[0m:\u001b[36mprocess_full_pipeline\u001b[0m:\u001b[36m301\u001b[0m - \u001b[1mStarting complete preprocessing pipeline...\u001b[0m\n",
      "\u001b[32m2025-08-06 17:01:51.687\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.data_preprocessor\u001b[0m:\u001b[36mengineer_features\u001b[0m:\u001b[36m140\u001b[0m - \u001b[1mFeature engineering completed. Added 6 new features\u001b[0m\n",
      "\u001b[32m2025-08-06 17:01:51.690\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.data_preprocessor\u001b[0m:\u001b[36mprepare_target_variable\u001b[0m:\u001b[36m160\u001b[0m - \u001b[1mTarget variable encoded: {'Approved': np.int64(0), 'Rejected': np.int64(1)}\u001b[0m\n",
      "\u001b[32m2025-08-06 17:01:51.698\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.data_preprocessor\u001b[0m:\u001b[36msplit_data\u001b[0m:\u001b[36m196\u001b[0m - \u001b[1mData split completed:\u001b[0m\n",
      "\u001b[32m2025-08-06 17:01:51.699\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.data_preprocessor\u001b[0m:\u001b[36msplit_data\u001b[0m:\u001b[36m197\u001b[0m - \u001b[1m  Train: 2774 samples\u001b[0m\n",
      "\u001b[32m2025-08-06 17:01:51.699\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.data_preprocessor\u001b[0m:\u001b[36msplit_data\u001b[0m:\u001b[36m198\u001b[0m - \u001b[1m  Validation: 641 samples\u001b[0m\n",
      "\u001b[32m2025-08-06 17:01:51.700\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.data_preprocessor\u001b[0m:\u001b[36msplit_data\u001b[0m:\u001b[36m199\u001b[0m - \u001b[1m  Test: 854 samples\u001b[0m\n",
      "\u001b[32m2025-08-06 17:01:51.721\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.data_preprocessor\u001b[0m:\u001b[36m_store_feature_names\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mStored 20 feature names\u001b[0m\n",
      "\u001b[32m2025-08-06 17:01:51.721\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.data_preprocessor\u001b[0m:\u001b[36mfit_transform_pipeline\u001b[0m:\u001b[36m224\u001b[0m - \u001b[1mPreprocessing pipeline fitted and applied successfully\u001b[0m\n",
      "\u001b[32m2025-08-06 17:01:51.722\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.data_preprocessor\u001b[0m:\u001b[36mfit_transform_pipeline\u001b[0m:\u001b[36m225\u001b[0m - \u001b[1mProcessed feature shape: (2774, 20)\u001b[0m\n",
      "\u001b[32m2025-08-06 17:01:51.724\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.data_preprocessor\u001b[0m:\u001b[36msave_preprocessor\u001b[0m:\u001b[36m272\u001b[0m - \u001b[1mPreprocessor saved to models\\preprocessor.joblib\u001b[0m\n",
      "\u001b[32m2025-08-06 17:01:51.725\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.data_preprocessor\u001b[0m:\u001b[36mprocess_full_pipeline\u001b[0m:\u001b[36m318\u001b[0m - \u001b[1mComplete preprocessing pipeline finished successfully\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set: (2774, 20)\n",
      "Validation Set: (641, 20)\n",
      "Test Set: (854, 20)\n",
      "Feature Names: 20 features\n",
      "\n",
      "✅ Data preprocessing completed\n"
     ]
    }
   ],
   "source": [
    "# Data preprocessing pipeline\n",
    "preprocessor = LoanDataPreprocessor()\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = preprocessor.process_full_pipeline(df)\n",
    "\n",
    "print(f\"Training Set: {X_train.shape}\")\n",
    "print(f\"Validation Set: {X_val.shape}\")\n",
    "print(f\"Test Set: {X_test.shape}\")\n",
    "print(f\"Feature Names: {len(preprocessor.feature_names)} features\")\n",
    "\n",
    "print(\"\\n✅ Data preprocessing completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Class Imbalance Analysis and Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-08-06 17:01:51.733\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.imbalance_handler\u001b[0m:\u001b[36manalyze_class_distribution\u001b[0m:\u001b[36m53\u001b[0m - \u001b[1mClass distribution analysis:\u001b[0m\n",
      "\u001b[32m2025-08-06 17:01:51.734\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.imbalance_handler\u001b[0m:\u001b[36manalyze_class_distribution\u001b[0m:\u001b[36m54\u001b[0m - \u001b[1m  Class counts: {0: 1726, 1: 1048}\u001b[0m\n",
      "\u001b[32m2025-08-06 17:01:51.734\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.imbalance_handler\u001b[0m:\u001b[36manalyze_class_distribution\u001b[0m:\u001b[36m55\u001b[0m - \u001b[1m  Imbalance ratio: 0.607\u001b[0m\n",
      "\u001b[32m2025-08-06 17:01:51.735\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.imbalance_handler\u001b[0m:\u001b[36manalyze_class_distribution\u001b[0m:\u001b[36m56\u001b[0m - \u001b[1m  Severely imbalanced: False\u001b[0m\n",
      "\u001b[32m2025-08-06 17:01:51.736\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.imbalance_handler\u001b[0m:\u001b[36manalyze_class_distribution\u001b[0m:\u001b[36m53\u001b[0m - \u001b[1mClass distribution analysis:\u001b[0m\n",
      "\u001b[32m2025-08-06 17:01:51.737\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.imbalance_handler\u001b[0m:\u001b[36manalyze_class_distribution\u001b[0m:\u001b[36m54\u001b[0m - \u001b[1m  Class counts: {0: 1726, 1: 1048}\u001b[0m\n",
      "\u001b[32m2025-08-06 17:01:51.738\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.imbalance_handler\u001b[0m:\u001b[36manalyze_class_distribution\u001b[0m:\u001b[36m55\u001b[0m - \u001b[1m  Imbalance ratio: 0.607\u001b[0m\n",
      "\u001b[32m2025-08-06 17:01:51.738\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.imbalance_handler\u001b[0m:\u001b[36manalyze_class_distribution\u001b[0m:\u001b[36m56\u001b[0m - \u001b[1m  Severely imbalanced: False\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Class Distribution:\n",
      "  Class Counts: {0: 1726, 1: 1048}\n",
      "  Imbalance Ratio: 0.607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-08-06 17:01:53.116\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.imbalance_handler\u001b[0m:\u001b[36mapply_smote\u001b[0m:\u001b[36m79\u001b[0m - \u001b[1mSMOTE applied:\u001b[0m\n",
      "\u001b[32m2025-08-06 17:01:53.117\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.imbalance_handler\u001b[0m:\u001b[36mapply_smote\u001b[0m:\u001b[36m80\u001b[0m - \u001b[1m  Original shape: (2774, 20)\u001b[0m\n",
      "\u001b[32m2025-08-06 17:01:53.118\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.imbalance_handler\u001b[0m:\u001b[36mapply_smote\u001b[0m:\u001b[36m81\u001b[0m - \u001b[1m  Resampled shape: (3452, 20)\u001b[0m\n",
      "\u001b[32m2025-08-06 17:01:53.118\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.imbalance_handler\u001b[0m:\u001b[36mapply_smote\u001b[0m:\u001b[36m82\u001b[0m - \u001b[1m  New class distribution: Counter({0: 1726, 1: 1726})\u001b[0m\n",
      "\u001b[32m2025-08-06 17:01:53.119\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.imbalance_handler\u001b[0m:\u001b[36mapply_best_resampling\u001b[0m:\u001b[36m219\u001b[0m - \u001b[1mApplied resampling method: smote\u001b[0m\n",
      "\u001b[32m2025-08-06 17:01:53.120\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.imbalance_handler\u001b[0m:\u001b[36manalyze_class_distribution\u001b[0m:\u001b[36m53\u001b[0m - \u001b[1mClass distribution analysis:\u001b[0m\n",
      "\u001b[32m2025-08-06 17:01:53.121\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.imbalance_handler\u001b[0m:\u001b[36manalyze_class_distribution\u001b[0m:\u001b[36m54\u001b[0m - \u001b[1m  Class counts: {0: 1726, 1: 1726}\u001b[0m\n",
      "\u001b[32m2025-08-06 17:01:53.122\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.imbalance_handler\u001b[0m:\u001b[36manalyze_class_distribution\u001b[0m:\u001b[36m55\u001b[0m - \u001b[1m  Imbalance ratio: 1.000\u001b[0m\n",
      "\u001b[32m2025-08-06 17:01:53.123\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.imbalance_handler\u001b[0m:\u001b[36manalyze_class_distribution\u001b[0m:\u001b[36m56\u001b[0m - \u001b[1m  Severely imbalanced: False\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After smote:\n",
      "  Class Counts: {0: 1726, 1: 1726}\n",
      "  Imbalance Ratio: 1.000\n",
      "\n",
      "✅ Class imbalance handling completed\n"
     ]
    }
   ],
   "source": [
    "# Handle class imbalance\n",
    "imbalance_handler = ImbalanceHandler()\n",
    "\n",
    "# Analyze original distribution\n",
    "original_distribution = imbalance_handler.analyze_class_distribution(y_train)\n",
    "print(\"Original Class Distribution:\")\n",
    "print(f\"  Class Counts: {original_distribution['class_counts']}\")\n",
    "print(f\"  Imbalance Ratio: {original_distribution['imbalance_ratio']:.3f}\")\n",
    "\n",
    "# Apply resampling\n",
    "X_train_balanced, y_train_balanced, resampling_method = imbalance_handler.apply_best_resampling(X_train, y_train)\n",
    "\n",
    "# Analyze new distribution\n",
    "new_distribution = imbalance_handler.analyze_class_distribution(y_train_balanced)\n",
    "print(f\"\\nAfter {resampling_method}:\")\n",
    "print(f\"  Class Counts: {new_distribution['class_counts']}\")\n",
    "print(f\"  Imbalance Ratio: {new_distribution['imbalance_ratio']:.3f}\")\n",
    "\n",
    "print(\"\\n✅ Class imbalance handling completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Training and Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-08-06 17:01:53.132\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_trainer\u001b[0m:\u001b[36mtrain_all_models\u001b[0m:\u001b[36m190\u001b[0m - \u001b[1mTraining 4 models: ['logistic_regression', 'decision_tree', 'random_forest', 'gradient_boosting']\u001b[0m\n",
      "\u001b[32m2025-08-06 17:01:53.132\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_trainer\u001b[0m:\u001b[36mtrain_single_model\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mTraining logistic_regression...\u001b[0m\n",
      "\u001b[32m2025-08-06 17:01:53.133\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_trainer\u001b[0m:\u001b[36mperform_hyperparameter_tuning\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mStarting hyperparameter tuning for logistic_regression...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-08-06 17:01:56.639\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_trainer\u001b[0m:\u001b[36mperform_hyperparameter_tuning\u001b[0m:\u001b[36m97\u001b[0m - \u001b[1mBest parameters for logistic_regression: {'C': 1.0, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear'}\u001b[0m\n",
      "\u001b[32m2025-08-06 17:01:56.640\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_trainer\u001b[0m:\u001b[36mperform_hyperparameter_tuning\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1mBest CV score for logistic_regression: 0.9771\u001b[0m\n",
      "\u001b[32m2025-08-06 17:01:56.827\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_trainer\u001b[0m:\u001b[36m_get_cv_scores\u001b[0m:\u001b[36m169\u001b[0m - \u001b[1m  PRECISION CV: 0.9663 (+/- 0.0284)\u001b[0m\n",
      "\u001b[32m2025-08-06 17:01:56.965\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_trainer\u001b[0m:\u001b[36m_get_cv_scores\u001b[0m:\u001b[36m169\u001b[0m - \u001b[1m  RECALL CV: 0.9884 (+/- 0.0132)\u001b[0m\n",
      "\u001b[32m2025-08-06 17:01:57.104\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_trainer\u001b[0m:\u001b[36m_get_cv_scores\u001b[0m:\u001b[36m169\u001b[0m - \u001b[1m  F1 CV: 0.9771 (+/- 0.0150)\u001b[0m\n",
      "\u001b[32m2025-08-06 17:01:57.233\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_trainer\u001b[0m:\u001b[36m_get_cv_scores\u001b[0m:\u001b[36m169\u001b[0m - \u001b[1m  ROC_AUC CV: 0.9951 (+/- 0.0053)\u001b[0m\n",
      "\u001b[32m2025-08-06 17:01:57.235\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_trainer\u001b[0m:\u001b[36mtrain_single_model\u001b[0m:\u001b[36m152\u001b[0m - \u001b[1mlogistic_regression training completed\u001b[0m\n",
      "\u001b[32m2025-08-06 17:01:57.235\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_trainer\u001b[0m:\u001b[36mtrain_single_model\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mTraining decision_tree...\u001b[0m\n",
      "\u001b[32m2025-08-06 17:01:57.236\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_trainer\u001b[0m:\u001b[36mperform_hyperparameter_tuning\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mStarting hyperparameter tuning for decision_tree...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-08-06 17:01:57.492\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_trainer\u001b[0m:\u001b[36mperform_hyperparameter_tuning\u001b[0m:\u001b[36m97\u001b[0m - \u001b[1mBest parameters for decision_tree: {'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 2}\u001b[0m\n",
      "\u001b[32m2025-08-06 17:01:57.493\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_trainer\u001b[0m:\u001b[36mperform_hyperparameter_tuning\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1mBest CV score for decision_tree: 0.9988\u001b[0m\n",
      "\u001b[32m2025-08-06 17:01:57.548\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_trainer\u001b[0m:\u001b[36m_get_cv_scores\u001b[0m:\u001b[36m169\u001b[0m - \u001b[1m  PRECISION CV: 0.9988 (+/- 0.0028)\u001b[0m\n",
      "\u001b[32m2025-08-06 17:01:57.590\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_trainer\u001b[0m:\u001b[36m_get_cv_scores\u001b[0m:\u001b[36m169\u001b[0m - \u001b[1m  RECALL CV: 0.9988 (+/- 0.0028)\u001b[0m\n",
      "\u001b[32m2025-08-06 17:01:57.632\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_trainer\u001b[0m:\u001b[36m_get_cv_scores\u001b[0m:\u001b[36m169\u001b[0m - \u001b[1m  F1 CV: 0.9988 (+/- 0.0022)\u001b[0m\n",
      "\u001b[32m2025-08-06 17:01:57.676\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_trainer\u001b[0m:\u001b[36m_get_cv_scores\u001b[0m:\u001b[36m169\u001b[0m - \u001b[1m  ROC_AUC CV: 0.9988 (+/- 0.0022)\u001b[0m\n",
      "\u001b[32m2025-08-06 17:01:57.677\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_trainer\u001b[0m:\u001b[36mtrain_single_model\u001b[0m:\u001b[36m152\u001b[0m - \u001b[1mdecision_tree training completed\u001b[0m\n",
      "\u001b[32m2025-08-06 17:01:57.677\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_trainer\u001b[0m:\u001b[36mtrain_single_model\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mTraining random_forest...\u001b[0m\n",
      "\u001b[32m2025-08-06 17:01:57.678\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_trainer\u001b[0m:\u001b[36mperform_hyperparameter_tuning\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mStarting hyperparameter tuning for random_forest...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-08-06 17:02:37.796\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_trainer\u001b[0m:\u001b[36mperform_hyperparameter_tuning\u001b[0m:\u001b[36m97\u001b[0m - \u001b[1mBest parameters for random_forest: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 100}\u001b[0m\n",
      "\u001b[32m2025-08-06 17:02:37.797\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_trainer\u001b[0m:\u001b[36mperform_hyperparameter_tuning\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1mBest CV score for random_forest: 0.9977\u001b[0m\n",
      "\u001b[32m2025-08-06 17:02:38.660\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_trainer\u001b[0m:\u001b[36m_get_cv_scores\u001b[0m:\u001b[36m169\u001b[0m - \u001b[1m  PRECISION CV: 0.9988 (+/- 0.0028)\u001b[0m\n",
      "\u001b[32m2025-08-06 17:02:39.413\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_trainer\u001b[0m:\u001b[36m_get_cv_scores\u001b[0m:\u001b[36m169\u001b[0m - \u001b[1m  RECALL CV: 0.9965 (+/- 0.0068)\u001b[0m\n",
      "\u001b[32m2025-08-06 17:02:40.162\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_trainer\u001b[0m:\u001b[36m_get_cv_scores\u001b[0m:\u001b[36m169\u001b[0m - \u001b[1m  F1 CV: 0.9977 (+/- 0.0039)\u001b[0m\n",
      "\u001b[32m2025-08-06 17:02:40.907\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_trainer\u001b[0m:\u001b[36m_get_cv_scores\u001b[0m:\u001b[36m169\u001b[0m - \u001b[1m  ROC_AUC CV: 0.9999 (+/- 0.0001)\u001b[0m\n",
      "\u001b[32m2025-08-06 17:02:40.960\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_trainer\u001b[0m:\u001b[36mtrain_single_model\u001b[0m:\u001b[36m152\u001b[0m - \u001b[1mrandom_forest training completed\u001b[0m\n",
      "\u001b[32m2025-08-06 17:02:40.961\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_trainer\u001b[0m:\u001b[36mtrain_single_model\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mTraining gradient_boosting...\u001b[0m\n",
      "\u001b[32m2025-08-06 17:02:40.961\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msrc.model_trainer\u001b[0m:\u001b[36mperform_hyperparameter_tuning\u001b[0m:\u001b[36m72\u001b[0m - \u001b[33m\u001b[1mNo hyperparameter configuration found for gradient_boosting. Using default parameters.\u001b[0m\n",
      "\u001b[32m2025-08-06 17:02:45.210\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_trainer\u001b[0m:\u001b[36m_get_cv_scores\u001b[0m:\u001b[36m169\u001b[0m - \u001b[1m  PRECISION CV: 1.0000 (+/- 0.0000)\u001b[0m\n",
      "\u001b[32m2025-08-06 17:02:48.606\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_trainer\u001b[0m:\u001b[36m_get_cv_scores\u001b[0m:\u001b[36m169\u001b[0m - \u001b[1m  RECALL CV: 0.9994 (+/- 0.0023)\u001b[0m\n",
      "\u001b[32m2025-08-06 17:02:51.934\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_trainer\u001b[0m:\u001b[36m_get_cv_scores\u001b[0m:\u001b[36m169\u001b[0m - \u001b[1m  F1 CV: 0.9997 (+/- 0.0012)\u001b[0m\n",
      "\u001b[32m2025-08-06 17:02:55.277\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_trainer\u001b[0m:\u001b[36m_get_cv_scores\u001b[0m:\u001b[36m169\u001b[0m - \u001b[1m  ROC_AUC CV: 1.0000 (+/- 0.0000)\u001b[0m\n",
      "\u001b[32m2025-08-06 17:02:55.281\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_trainer\u001b[0m:\u001b[36mtrain_single_model\u001b[0m:\u001b[36m152\u001b[0m - \u001b[1mgradient_boosting training completed\u001b[0m\n",
      "\u001b[32m2025-08-06 17:02:55.281\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_trainer\u001b[0m:\u001b[36mtrain_all_models\u001b[0m:\u001b[36m202\u001b[0m - \u001b[1mAll model training completed\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results Summary:\n",
      "\n",
      "LOGISTIC_REGRESSION:\n",
      "  precision: 0.9663 (+/- 0.0284)\n",
      "  recall: 0.9884 (+/- 0.0132)\n",
      "  f1: 0.9771 (+/- 0.0150)\n",
      "  roc_auc: 0.9951 (+/- 0.0053)\n",
      "\n",
      "DECISION_TREE:\n",
      "  precision: 0.9988 (+/- 0.0028)\n",
      "  recall: 0.9988 (+/- 0.0028)\n",
      "  f1: 0.9988 (+/- 0.0022)\n",
      "  roc_auc: 0.9988 (+/- 0.0022)\n",
      "\n",
      "RANDOM_FOREST:\n",
      "  precision: 0.9988 (+/- 0.0028)\n",
      "  recall: 0.9965 (+/- 0.0068)\n",
      "  f1: 0.9977 (+/- 0.0039)\n",
      "  roc_auc: 0.9999 (+/- 0.0001)\n",
      "\n",
      "GRADIENT_BOOSTING:\n",
      "  precision: 1.0000 (+/- 0.0000)\n",
      "  recall: 0.9994 (+/- 0.0023)\n",
      "  f1: 0.9997 (+/- 0.0012)\n",
      "  roc_auc: 1.0000 (+/- 0.0000)\n",
      "\n",
      "✅ Model training completed\n"
     ]
    }
   ],
   "source": [
    "# Train multiple models\n",
    "trainer = ModelTrainer()\n",
    "training_results = trainer.train_all_models(X_train_balanced, y_train_balanced, X_val, y_val)\n",
    "\n",
    "print(\"Training Results Summary:\")\n",
    "for model_name, results in training_results.items():\n",
    "    cv_scores = results['cv_scores']\n",
    "    print(f\"\\n{model_name.upper()}:\")\n",
    "    for metric, scores in cv_scores.items():\n",
    "        mean_score = np.mean(scores)\n",
    "        std_score = np.std(scores)\n",
    "        print(f\"  {metric}: {mean_score:.4f} (+/- {std_score * 2:.4f})\")\n",
    "\n",
    "print(\"\\n✅ Model training completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Evaluation and Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-08-06 17:02:55.291\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_evaluator\u001b[0m:\u001b[36mevaluate_single_model\u001b[0m:\u001b[36m53\u001b[0m - \u001b[1mEvaluating model: logistic_regression\u001b[0m\n",
      "\u001b[32m2025-08-06 17:02:55.306\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_evaluator\u001b[0m:\u001b[36mevaluate_single_model\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mEvaluation completed for logistic_regression\u001b[0m\n",
      "\u001b[32m2025-08-06 17:02:55.307\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_evaluator\u001b[0m:\u001b[36mevaluate_single_model\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1m  Accuracy: 0.9731\u001b[0m\n",
      "\u001b[32m2025-08-06 17:02:55.308\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_evaluator\u001b[0m:\u001b[36mevaluate_single_model\u001b[0m:\u001b[36m89\u001b[0m - \u001b[1m  Precision: 0.9518\u001b[0m\n",
      "\u001b[32m2025-08-06 17:02:55.308\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_evaluator\u001b[0m:\u001b[36mevaluate_single_model\u001b[0m:\u001b[36m90\u001b[0m - \u001b[1m  Recall: 0.9783\u001b[0m\n",
      "\u001b[32m2025-08-06 17:02:55.308\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_evaluator\u001b[0m:\u001b[36mevaluate_single_model\u001b[0m:\u001b[36m91\u001b[0m - \u001b[1m  F1-Score: 0.9649\u001b[0m\n",
      "\u001b[32m2025-08-06 17:02:55.308\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_evaluator\u001b[0m:\u001b[36mevaluate_single_model\u001b[0m:\u001b[36m53\u001b[0m - \u001b[1mEvaluating model: decision_tree\u001b[0m\n",
      "\u001b[32m2025-08-06 17:02:55.319\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_evaluator\u001b[0m:\u001b[36mevaluate_single_model\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mEvaluation completed for decision_tree\u001b[0m\n",
      "\u001b[32m2025-08-06 17:02:55.320\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_evaluator\u001b[0m:\u001b[36mevaluate_single_model\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1m  Accuracy: 1.0000\u001b[0m\n",
      "\u001b[32m2025-08-06 17:02:55.320\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_evaluator\u001b[0m:\u001b[36mevaluate_single_model\u001b[0m:\u001b[36m89\u001b[0m - \u001b[1m  Precision: 1.0000\u001b[0m\n",
      "\u001b[32m2025-08-06 17:02:55.321\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_evaluator\u001b[0m:\u001b[36mevaluate_single_model\u001b[0m:\u001b[36m90\u001b[0m - \u001b[1m  Recall: 1.0000\u001b[0m\n",
      "\u001b[32m2025-08-06 17:02:55.321\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_evaluator\u001b[0m:\u001b[36mevaluate_single_model\u001b[0m:\u001b[36m91\u001b[0m - \u001b[1m  F1-Score: 1.0000\u001b[0m\n",
      "\u001b[32m2025-08-06 17:02:55.321\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_evaluator\u001b[0m:\u001b[36mevaluate_single_model\u001b[0m:\u001b[36m53\u001b[0m - \u001b[1mEvaluating model: random_forest\u001b[0m\n",
      "\u001b[32m2025-08-06 17:02:55.418\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_evaluator\u001b[0m:\u001b[36mevaluate_single_model\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mEvaluation completed for random_forest\u001b[0m\n",
      "\u001b[32m2025-08-06 17:02:55.419\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_evaluator\u001b[0m:\u001b[36mevaluate_single_model\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1m  Accuracy: 0.9988\u001b[0m\n",
      "\u001b[32m2025-08-06 17:02:55.419\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_evaluator\u001b[0m:\u001b[36mevaluate_single_model\u001b[0m:\u001b[36m89\u001b[0m - \u001b[1m  Precision: 0.9969\u001b[0m\n",
      "\u001b[32m2025-08-06 17:02:55.419\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_evaluator\u001b[0m:\u001b[36mevaluate_single_model\u001b[0m:\u001b[36m90\u001b[0m - \u001b[1m  Recall: 1.0000\u001b[0m\n",
      "\u001b[32m2025-08-06 17:02:55.420\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_evaluator\u001b[0m:\u001b[36mevaluate_single_model\u001b[0m:\u001b[36m91\u001b[0m - \u001b[1m  F1-Score: 0.9985\u001b[0m\n",
      "\u001b[32m2025-08-06 17:02:55.420\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_evaluator\u001b[0m:\u001b[36mevaluate_single_model\u001b[0m:\u001b[36m53\u001b[0m - \u001b[1mEvaluating model: gradient_boosting\u001b[0m\n",
      "\u001b[32m2025-08-06 17:02:55.434\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_evaluator\u001b[0m:\u001b[36mevaluate_single_model\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mEvaluation completed for gradient_boosting\u001b[0m\n",
      "\u001b[32m2025-08-06 17:02:55.435\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_evaluator\u001b[0m:\u001b[36mevaluate_single_model\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1m  Accuracy: 1.0000\u001b[0m\n",
      "\u001b[32m2025-08-06 17:02:55.435\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_evaluator\u001b[0m:\u001b[36mevaluate_single_model\u001b[0m:\u001b[36m89\u001b[0m - \u001b[1m  Precision: 1.0000\u001b[0m\n",
      "\u001b[32m2025-08-06 17:02:55.435\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_evaluator\u001b[0m:\u001b[36mevaluate_single_model\u001b[0m:\u001b[36m90\u001b[0m - \u001b[1m  Recall: 1.0000\u001b[0m\n",
      "\u001b[32m2025-08-06 17:02:55.436\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_evaluator\u001b[0m:\u001b[36mevaluate_single_model\u001b[0m:\u001b[36m91\u001b[0m - \u001b[1m  F1-Score: 1.0000\u001b[0m\n",
      "\u001b[32m2025-08-06 17:02:55.436\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_evaluator\u001b[0m:\u001b[36mgenerate_evaluation_report\u001b[0m:\u001b[36m229\u001b[0m - \u001b[1mGenerating comprehensive evaluation report...\u001b[0m\n",
      "\u001b[32m2025-08-06 17:02:55.437\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_evaluator\u001b[0m:\u001b[36mcompare_models\u001b[0m:\u001b[36m165\u001b[0m - \u001b[1mComparing model performances...\u001b[0m\n",
      "\u001b[32m2025-08-06 17:02:55.439\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_evaluator\u001b[0m:\u001b[36mcompare_models\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mModel comparison completed. Recommended model: decision_tree\u001b[0m\n",
      "\u001b[32m2025-08-06 17:02:55.441\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_evaluator\u001b[0m:\u001b[36mgenerate_evaluation_report\u001b[0m:\u001b[36m250\u001b[0m - \u001b[1mEvaluation report saved to results\\evaluation_report.json\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance Comparison:\n",
      "                 Model  Accuracy  Precision  Recall  F1-Score  ROC-AUC  \\\n",
      "0  logistic_regression    0.9731     0.9518  0.9783    0.9649   0.9955   \n",
      "1        decision_tree    1.0000     1.0000  1.0000    1.0000   1.0000   \n",
      "2        random_forest    0.9988     0.9969  1.0000    0.9985   1.0000   \n",
      "3    gradient_boosting    1.0000     1.0000  1.0000    1.0000   1.0000   \n",
      "\n",
      "   Type I Error Rate  Type II Error Rate  \n",
      "0             0.0301              0.0217  \n",
      "1             0.0000              0.0000  \n",
      "2             0.0019              0.0000  \n",
      "3             0.0000              0.0000  \n",
      "\n",
      "Recommended Model: decision_tree\n",
      "Reason: Best F1 score for imbalanced classification\n",
      "\n",
      "✅ Model evaluation completed\n"
     ]
    }
   ],
   "source": [
    "# Comprehensive model evaluation\n",
    "evaluator = ModelEvaluator(feature_names=preprocessor.feature_names)\n",
    "\n",
    "# Evaluate each model on test set\n",
    "evaluation_results = {}\n",
    "for model_name, model in trainer.models.items():\n",
    "    results = evaluator.evaluate_single_model(model, model_name, X_test, y_test)\n",
    "    evaluation_results[model_name] = results\n",
    "\n",
    "# Generate evaluation report\n",
    "evaluation_report = evaluator.generate_evaluation_report(evaluation_results)\n",
    "\n",
    "# Display performance summary\n",
    "comparison_df = pd.DataFrame(evaluation_report['model_comparison']['comparison_table'])\n",
    "print(\"Model Performance Comparison:\")\n",
    "print(comparison_df.round(4))\n",
    "\n",
    "print(f\"\\nRecommended Model: {evaluation_report['model_comparison']['recommended_model']}\")\n",
    "print(f\"Reason: {evaluation_report['model_comparison']['recommendation_reason']}\")\n",
    "\n",
    "print(\"\\n✅ Model evaluation completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-08-06 17:02:55.452\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.evaluation_visualizer\u001b[0m:\u001b[36mcreate_evaluation_dashboard\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mCreating comprehensive evaluation dashboard...\u001b[0m\n",
      "\u001b[32m2025-08-06 17:02:58.424\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.evaluation_visualizer\u001b[0m:\u001b[36mcreate_evaluation_dashboard\u001b[0m:\u001b[36m365\u001b[0m - \u001b[1mEvaluation dashboard created successfully\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Evaluation visualizations created\n"
     ]
    }
   ],
   "source": [
    "# Create comprehensive evaluation visualizations\n",
    "viz = EvaluationVisualizer()\n",
    "viz.create_evaluation_dashboard(\n",
    "    evaluation_results, y_test, trainer.models, X_test, \n",
    "    evaluation_report['model_comparison']\n",
    ")\n",
    "\n",
    "print(\"✅ Evaluation visualizations created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Production Pipeline Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-08-06 17:02:58.433\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_evaluator\u001b[0m:\u001b[36mselect_best_model\u001b[0m:\u001b[36m309\u001b[0m - \u001b[1mBest model selected: decision_tree with f1: 1.0000\u001b[0m\n",
      "\u001b[32m2025-08-06 17:02:58.435\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_trainer\u001b[0m:\u001b[36msave_model\u001b[0m:\u001b[36m264\u001b[0m - \u001b[1mModel saved to models\\decision_tree_model.joblib\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model (decision_tree) saved to: models\\decision_tree_model.joblib\n",
      "Performance Metrics: {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'roc_auc': np.float64(1.0)}\n",
      "\n",
      "✅ Production pipeline setup completed\n"
     ]
    }
   ],
   "source": [
    "# Select and save best model for production\n",
    "best_model_name, best_model = evaluator.select_best_model(evaluation_results)\n",
    "\n",
    "# Get performance metrics\n",
    "best_model_results = evaluation_results[best_model_name]\n",
    "performance_metrics = {\n",
    "    'accuracy': best_model_results['accuracy'],\n",
    "    'precision': best_model_results['precision'],\n",
    "    'recall': best_model_results['recall'],\n",
    "    'f1_score': best_model_results['f1_score'],\n",
    "    'roc_auc': best_model_results.get('roc_auc', 0)\n",
    "}\n",
    "\n",
    "# Save model for production\n",
    "model_path = trainer.save_model(\n",
    "    best_model, \n",
    "    best_model_name, \n",
    "    {\n",
    "        'performance_metrics': performance_metrics,\n",
    "        'resampling_method': resampling_method,\n",
    "        'feature_names': preprocessor.feature_names\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"Best model ({best_model_name}) saved to: {model_path}\")\n",
    "print(f\"Performance Metrics: {performance_metrics}\")\n",
    "\n",
    "print(\"\\n✅ Production pipeline setup completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Production Inference Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-08-06 17:07:04.197\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.production_pipeline\u001b[0m:\u001b[36mregister_model\u001b[0m:\u001b[36m483\u001b[0m - \u001b[1mModel registered: decision_tree_v15_20250806_170704\u001b[0m\n",
      "\u001b[32m2025-08-06 17:07:04.200\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.production_pipeline\u001b[0m:\u001b[36mset_active_model\u001b[0m:\u001b[36m500\u001b[0m - \u001b[1mActive model set to: decision_tree_v15_20250806_170704\u001b[0m\n",
      "\u001b[32m2025-08-06 17:07:04.202\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.production_pipeline\u001b[0m:\u001b[36m_load_artifacts\u001b[0m:\u001b[36m93\u001b[0m - \u001b[1mPreprocessor loaded successfully\u001b[0m\n",
      "\u001b[32m2025-08-06 17:07:04.204\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.production_pipeline\u001b[0m:\u001b[36m_load_artifacts\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mModel loaded successfully\u001b[0m\n",
      "\u001b[32m2025-08-06 17:07:04.205\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.production_pipeline\u001b[0m:\u001b[36mcreate_production_pipeline\u001b[0m:\u001b[36m546\u001b[0m - \u001b[1mProduction pipeline created and configured successfully\u001b[0m\n",
      "\u001b[32m2025-08-06 17:07:04.217\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.production_pipeline\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mPrediction made: Rejected (confidence: 1.000)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Production Pipeline Test:\n",
      "  Loan ID: DEMO_001\n",
      "  Prediction: Rejected\n",
      "  Confidence: 1.000\n",
      "  Risk Score: 0.000\n",
      "  Key Factors: ['credit_score_category_Poor', 'debt_to_income_ratio', 'loan_term', 'High confidence prediction']\n",
      "\n",
      "Pipeline Health: healthy\n",
      "\n",
      "✅ Production pipeline testing completed\n"
     ]
    }
   ],
   "source": [
    "# Test production pipeline\n",
    "from src.production_pipeline import create_production_pipeline\n",
    "\n",
    "# Create production pipeline\n",
    "prod_pipeline = create_production_pipeline(best_model_name, model_path, performance_metrics)\n",
    "\n",
    "# Test with sample application\n",
    "sample_application = {\n",
    "    \"loan_id\": \"DEMO_001\",\n",
    "    \"no_of_dependents\": 2,\n",
    "    \"education\": \"Graduate\",\n",
    "    \"self_employed\": \"No\",\n",
    "    \"income_annum\": 6000000.0,\n",
    "    \"loan_amount\": 18000000.0,\n",
    "    \"loan_term\": 15,\n",
    "    \"cibil_score\": 780,\n",
    "    \"residential_assets_value\": 2500000.0,\n",
    "    \"commercial_assets_value\": 1200000.0,\n",
    "    \"luxury_assets_value\": 600000.0,\n",
    "    \"bank_asset_value\": 400000.0\n",
    "}\n",
    "\n",
    "# Create DataFrame from sample application (raw input)\n",
    "import pandas as pd\n",
    "sample_df = pd.DataFrame([sample_application])\n",
    "\n",
    "# Make prediction using the raw DataFrame (let pipeline handle preprocessing)\n",
    "prediction_response = prod_pipeline.predict(sample_df.iloc[0].to_dict())\n",
    "\n",
    "print(\"Production Pipeline Test:\")\n",
    "print(f\"  Loan ID: {prediction_response.loan_id}\")\n",
    "print(f\"  Prediction: {prediction_response.prediction}\")\n",
    "print(f\"  Confidence: {prediction_response.confidence:.3f}\")\n",
    "print(f\"  Risk Score: {prediction_response.risk_score:.3f}\")\n",
    "print(f\"  Key Factors: {prediction_response.key_factors}\")\n",
    "\n",
    "# Health check\n",
    "health_status = prod_pipeline.health_check()\n",
    "print(f\"\\nPipeline Health: {health_status['status']}\")\n",
    "\n",
    "print(\"\\n✅ Production pipeline testing completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Business Impact Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BUSINESS IMPACT ANALYSIS\n",
      "==================================================\n",
      "Model: decision_tree\n",
      "\n",
      "Prediction Accuracy: 100.0%\n",
      "Precision (Bad Loan Avoidance): 100.0%\n",
      "Recall (Good Loan Capture): 100.0%\n",
      "F1-Score (Balanced Performance): 100.0%\n",
      "\n",
      "BUSINESS RISK METRICS:\n",
      "Type I Error Rate (Bad Loans Approved): 0.0%\n",
      "Type II Error Rate (Good Loans Rejected): 0.0%\n",
      "Cost Ratio (Financial Risk): 0.0%\n",
      "Opportunity Loss Ratio: 0.0%\n",
      "\n",
      "CONFUSION MATRIX BREAKDOWN:\n",
      "True Positives (Correctly Approved): 323\n",
      "True Negatives (Correctly Rejected): 531\n",
      "False Positives (Incorrectly Approved): 0\n",
      "False Negatives (Incorrectly Rejected): 0\n"
     ]
    }
   ],
   "source": [
    "# Analyze business impact of the best model\n",
    "best_results = evaluation_results[best_model_name]\n",
    "business_metrics = best_results['business_metrics']\n",
    "\n",
    "print(\"BUSINESS IMPACT ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(f\"Model: {best_model_name}\")\n",
    "print(f\"\\nPrediction Accuracy: {best_results['accuracy']:.1%}\")\n",
    "print(f\"Precision (Bad Loan Avoidance): {best_results['precision']:.1%}\")\n",
    "print(f\"Recall (Good Loan Capture): {best_results['recall']:.1%}\")\n",
    "print(f\"F1-Score (Balanced Performance): {best_results['f1_score']:.1%}\")\n",
    "\n",
    "print(f\"\\nBUSINESS RISK METRICS:\")\n",
    "print(f\"Type I Error Rate (Bad Loans Approved): {business_metrics['type_i_error_rate']:.1%}\")\n",
    "print(f\"Type II Error Rate (Good Loans Rejected): {business_metrics['type_ii_error_rate']:.1%}\")\n",
    "print(f\"Cost Ratio (Financial Risk): {business_metrics['cost_ratio']:.1%}\")\n",
    "print(f\"Opportunity Loss Ratio: {business_metrics['opportunity_loss_ratio']:.1%}\")\n",
    "\n",
    "print(f\"\\nCONFUSION MATRIX BREAKDOWN:\")\n",
    "print(f\"True Positives (Correctly Approved): {business_metrics['true_positives']}\")\n",
    "print(f\"True Negatives (Correctly Rejected): {business_metrics['true_negatives']}\")\n",
    "print(f\"False Positives (Incorrectly Approved): {business_metrics['false_positives']}\")\n",
    "print(f\"False Negatives (Incorrectly Rejected): {business_metrics['false_negatives']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Model Interpretability and Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP 10 MOST IMPORTANT FEATURES:\n",
      "========================================\n",
      " 1. credit_score_category_Poor 0.8544\n",
      " 2. debt_to_income_ratio      0.0751\n",
      " 3. loan_term                 0.0533\n",
      " 4. loan_to_asset_ratio       0.0149\n",
      " 5. cibil_score               0.0023\n",
      " 6. no_of_dependents          0.0000\n",
      " 7. income_annum              0.0000\n",
      " 8. loan_amount               0.0000\n",
      " 9. residential_assets_value  0.0000\n",
      "10. commercial_assets_value   0.0000\n",
      "\n",
      "✅ Feature importance analysis completed\n"
     ]
    }
   ],
   "source": [
    "# Feature importance analysis\n",
    "if 'feature_importance' in best_results:\n",
    "    feature_importance = best_results['feature_importance']\n",
    "    print(\"TOP 10 MOST IMPORTANT FEATURES:\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    for i, (feature, importance) in enumerate(list(feature_importance.items())[:10], 1):\n",
    "        print(f\"{i:2d}. {feature:<25} {importance:.4f}\")\n",
    "\n",
    "elif 'feature_coefficients' in best_results:\n",
    "    feature_coef = best_results['feature_coefficients']\n",
    "    print(\"TOP 10 MOST INFLUENTIAL FEATURES (by coefficient magnitude):\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for i, (feature, coef) in enumerate(list(feature_coef.items())[:10], 1):\n",
    "        direction = \"↑ Increases\" if coef > 0 else \"↓ Decreases\"\n",
    "        print(f\"{i:2d}. {feature:<25} {coef:8.4f} ({direction} approval probability)\")\n",
    "\n",
    "print(\"\\n✅ Feature importance analysis completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Final Recommendations and Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL RECOMMENDATIONS\n",
      "==================================================\n",
      "\n",
      "🎯 BUSINESS RECOMMENDATIONS:\n",
      "  1. Deploy the trained model to automate initial loan screening\n",
      "  2. Focus on precision to minimize bad loan approvals and reduce financial risk\n",
      "  3. Implement manual review for borderline cases (confidence < 70%)\n",
      "  4. Monitor model performance monthly and retrain quarterly\n",
      "  5. Use model insights to improve loan application process\n",
      "\n",
      "🔧 TECHNICAL RECOMMENDATIONS:\n",
      "  1. Deploy using the provided FastAPI service for scalable predictions\n",
      "  2. Implement model monitoring to track prediction drift\n",
      "  3. Set up automated retraining pipeline with new data\n",
      "  4. Use A/B testing for model improvements\n",
      "  5. Implement comprehensive logging and error handling\n",
      "\n",
      "📊 NEXT STEPS:\n",
      "  1. Run the API server: python src/api_server.py\n",
      "  2. Execute tests: pytest tests/\n",
      "  3. Review results in the 'results' folder\n",
      "  4. Deploy to production environment\n",
      "  5. Set up monitoring and alerting\n",
      "\n",
      "================================================================================\n",
      "🎉 LOAN APPROVAL PREDICTION PIPELINE COMPLETED SUCCESSFULLY!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"FINAL RECOMMENDATIONS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"\\n🎯 BUSINESS RECOMMENDATIONS:\")\n",
    "business_recommendations = [\n",
    "    \"Deploy the trained model to automate initial loan screening\",\n",
    "    \"Focus on precision to minimize bad loan approvals and reduce financial risk\",\n",
    "    \"Implement manual review for borderline cases (confidence < 70%)\",\n",
    "    \"Monitor model performance monthly and retrain quarterly\",\n",
    "    \"Use model insights to improve loan application process\"\n",
    "]\n",
    "\n",
    "for i, rec in enumerate(business_recommendations, 1):\n",
    "    print(f\"  {i}. {rec}\")\n",
    "\n",
    "print(\"\\n🔧 TECHNICAL RECOMMENDATIONS:\")\n",
    "technical_recommendations = [\n",
    "    \"Deploy using the provided FastAPI service for scalable predictions\",\n",
    "    \"Implement model monitoring to track prediction drift\",\n",
    "    \"Set up automated retraining pipeline with new data\",\n",
    "    \"Use A/B testing for model improvements\",\n",
    "    \"Implement comprehensive logging and error handling\"\n",
    "]\n",
    "\n",
    "for i, rec in enumerate(technical_recommendations, 1):\n",
    "    print(f\"  {i}. {rec}\")\n",
    "\n",
    "print(\"\\n📊 NEXT STEPS:\")\n",
    "next_steps = [\n",
    "    \"Run the API server: python src/api_server.py\",\n",
    "    \"Execute tests: pytest tests/\",\n",
    "    \"Review results in the 'results' folder\",\n",
    "    \"Deploy to production environment\",\n",
    "    \"Set up monitoring and alerting\"\n",
    "]\n",
    "\n",
    "for i, step in enumerate(next_steps, 1):\n",
    "    print(f\"  {i}. {step}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"🎉 LOAN APPROVAL PREDICTION PIPELINE COMPLETED SUCCESSFULLY!\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
